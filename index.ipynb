{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2921b8d1",
   "metadata": {},
   "source": [
    "<center><img src=\"https://github.com/DACSS-CSSmeths/guidelines/blob/main/pics/small_logo_ccs_meths.jpg?raw=true\" width=\"700\"></center>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Insight from your GeoDataFrame\n",
    "\n",
    "This final session covers two main topics:\n",
    "\n",
    "* The computation of spatial distances\n",
    "\n",
    "* The computation of spatial indicators from the spatial data\n",
    "\n",
    "Let me first check what I have in the map geopackage file from Brazil, already reprojected:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6c03fb-08dc-42d2-999c-ef1315ddb32f",
   "metadata": {},
   "source": [
    "# II. MINING SPATIAL DATA\n",
    "\n",
    "It is time to use  *dataPeru_indicadores.xlsx* file and the  map of Peruvian districts: *DistritosMap.zip* (zipped shape file).\n",
    "\n",
    "Let's read the data in :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "138f73c3-37b8-47c4-8645-8e858bc83811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n"
     ]
    }
   ],
   "source": [
    "# !pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cad54a69-3198-4ae0-b561-b786dc0c4c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1874 entries, 0 to 1873\n",
      "Data columns (total 10 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Ubigeo                    1874 non-null   object \n",
      " 1   Departamento              1874 non-null   object \n",
      " 2   Provincia                 1874 non-null   object \n",
      " 3   Distrito                  1874 non-null   object \n",
      " 4   Poblacion                 1874 non-null   int64  \n",
      " 5   Superficie                1874 non-null   float64\n",
      " 6   IDH2019                   1874 non-null   float64\n",
      " 7   Educ_sec_comp2019_pct     1874 non-null   float64\n",
      " 8   NBI2017_pct               1874 non-null   float64\n",
      " 9   Viv_sin_serv_hig2017_pct  1874 non-null   float64\n",
      "dtypes: float64(5), int64(1), object(4)\n",
      "memory usage: 146.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# data table\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "peruDataLink=\"https://github.com/CienciaDeDatosEspacial/GeoDataFrame_Analytics/raw/main/data/dataPeru_indicadores.xlsx\"\n",
    "datadis=pd.read_excel(peruDataLink,\n",
    "                     dtype={'Ubigeo': object})\n",
    "datadis.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a840636-49ab-4a6d-9bb6-0e344822e3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 1874 entries, 0 to 1873\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   DEPARTAMEN  1874 non-null   object  \n",
      " 1   PROVINCIA   1874 non-null   object  \n",
      " 2   DISTRITO    1874 non-null   object  \n",
      " 3   INSTITUCIO  1874 non-null   object  \n",
      " 4   geometry    1874 non-null   geometry\n",
      "dtypes: geometry(1), object(4)\n",
      "memory usage: 73.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# map\n",
    "import geopandas as gpd\n",
    "\n",
    "peruMapaDistLink=\"https://github.com/CienciaDeDatosEspacial/GeoDataFrame_Analytics/raw/main/maps/DistritosMap.zip\"\n",
    "\n",
    "mapdis=gpd.read_file(peruMapaDistLink)\n",
    "\n",
    "mapdis.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e234648d-afd8-49b0-9af6-f02e23461d82",
   "metadata": {},
   "source": [
    "Next we will merge the indicators table into the map."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4de5282-8a5b-45d8-9ced-6c3690a15b42",
   "metadata": {},
   "source": [
    "## Merging\n",
    "\n",
    "When merging, verify the amount of resulting rows first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d0789a7-be19-4eb2-a5d0-66aae882a93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2323, 15)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapdis.merge(datadis, left_on='DISTRITO', right_on='Distrito').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76ed070-616f-4199-a6b0-48f1c80abff6",
   "metadata": {},
   "source": [
    "The amount of rows increases when merged. Let's do some preprocessing:\n",
    "\n",
    "1. Capitalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d21b724-8212-4bed-88c9-fa9858330f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all capitals, no empty spaces before or after.\n",
    "\n",
    "capitalizeColumns=lambda x: x.str.upper().str.strip()\n",
    "datadis[['Provincia','Distrito']]=datadis[['Provincia','Distrito']].apply(capitalizeColumns)\n",
    "mapdis[['PROVINCIA','DISTRITO']]=mapdis[['PROVINCIA','DISTRITO']].apply(capitalizeColumns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce410db-12e2-405a-83e2-0bf822da1c48",
   "metadata": {},
   "source": [
    "2. Spanish symbols: The names may come with some symbols that may cause trouble (', ~). Let's get rid of those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cde441d5-53b8-45ab-9af2-0f9b895e9088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unidecode\n",
      "  Using cached Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
      "Installing collected packages: unidecode\n",
      "Successfully installed unidecode-1.3.8\n"
     ]
    }
   ],
   "source": [
    "# !pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0aebbfce-ff05-4b8d-938a-c8c50a21d798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "\n",
    "\n",
    "byePunctuation=lambda x: unidecode.unidecode(x)\n",
    "datadis[['Provincia','Distrito']]=datadis[['Provincia','Distrito']].map(byePunctuation)  #applymap for olderpandas\n",
    "mapdis[['PROVINCIA','DISTRITO']]=mapdis[['PROVINCIA','DISTRITO']].map(byePunctuation) #applymap for olderpandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d744c9a9-fd9c-4138-b135-4f7d675354ae",
   "metadata": {},
   "source": [
    "3. Check uniqueness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c33a551-51a1-4225-86a6-b6d9ae27b12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(154), np.int64(152))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadis.Distrito.duplicated().sum(),mapdis.DISTRITO.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d3ae42-d0ed-4e6c-a114-3517b2351216",
   "metadata": {},
   "source": [
    "The presence of duplicates, forces we create  a column of unique values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50782d60-96b3-4fda-8731-a236a45d8216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating\n",
    "datadis['provDist']=[\"+\".join(pd) for pd in zip (datadis.Provincia,datadis.Distrito)]\n",
    "mapdis['provDist']=[\"+\".join(pd) for pd in zip (mapdis.PROVINCIA,mapdis.DISTRITO)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca51a1a7-9979-4837-b042-4bc7baffbcc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    BAGUA+ARAMANGO\n",
       "1       BAGUA+BAGUA\n",
       "2    BAGUA+COPALLIN\n",
       "3    BAGUA+EL PARCO\n",
       "4       BAGUA+IMAZA\n",
       "Name: provDist, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the new column looks like this:\n",
    "datadis['provDist'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43aaa1a8-f47d-474c-b465-bada8c5fb40d",
   "metadata": {},
   "source": [
    "Let's find out what is NOT matched between the  tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25ed7646-6dbd-488f-9445-798c3d33d1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nomatch_df=set(datadis.provDist)- set(mapdis.provDist)\n",
    "nomatch_gdf=set(mapdis.provDist)-set(datadis.provDist) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b8fc82-e9b9-412c-801d-fa0ce0f5f27f",
   "metadata": {},
   "source": [
    "This is the amount of rows that could not be matched:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e958add0-261c-42d4-94ca-fc81ad5a1be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 26)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nomatch_df), len(nomatch_gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc7a671-ccfa-43e9-99c7-61a44f54fccf",
   "metadata": {},
   "source": [
    "Let's try renaming the districts using **fuzzy merging**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e20ea6bf-9e69-4233-8529-52fd49d2719a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting thefuzz\n",
      "  Downloading thefuzz-0.22.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting rapidfuzz<4.0.0,>=3.0.0 (from thefuzz)\n",
      "  Downloading rapidfuzz-3.12.1-cp313-cp313-macosx_10_13_x86_64.whl.metadata (11 kB)\n",
      "Downloading thefuzz-0.22.1-py3-none-any.whl (8.2 kB)\n",
      "Downloading rapidfuzz-3.12.1-cp313-cp313-macosx_10_13_x86_64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Installing collected packages: rapidfuzz, thefuzz\n",
      "Successfully installed rapidfuzz-3.12.1 thefuzz-0.22.1\n"
     ]
    }
   ],
   "source": [
    "!pip install thefuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87f6e31a-35da-4cc9-a92c-c1cb1ea09313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ANGARAES+HUANCA-HUANCA', ('ANGARAES+HUANCA HUANCA', 100)),\n",
       " ('ANGARAES+HUAYLLAY GRANDE', ('ANGARAES+HUALLAY GRANDE', 98)),\n",
       " ('AYMARAES+CARAYBAMBA', ('AYMARAES+CARAIBAMBA', 95)),\n",
       " ('AYMARAES+HUAYLLO', ('AYMARAES+IHUAYLLO', 97)),\n",
       " ('CHINCHEROS+ANCO_HUALLO', ('CHINCHEROS+ANCO HUALLO', 100)),\n",
       " ('HUAMANGA+SAN JOSE DE TICLLAS', ('HUAMANGA+SAN JOSE  DE TICLLAS', 98)),\n",
       " ('HUARAZ+PAMPAS', ('HUARAZ+PAMPAS GRANDE', 90)),\n",
       " ('ICA+SAN JOSE DE LOS MOLINOS', ('ICA+SAN JOSE DE  LOS MOLINOS', 98)),\n",
       " ('JAUJA+MASMA CHICCHE', ('JAUJA+MASMA-CHICCHE', 100)),\n",
       " ('JAUJA+TUNAN MARCA', ('JAUJA+TUNAN-MARCA', 100)),\n",
       " ('LEONCIO PRADO+DANIEL ALOMIAS ROBLES',\n",
       "  ('LEONCIO PRADO+DANIEL ALOMIA ROBLES', 99)),\n",
       " ('LIMA+PUEBLO LIBRE', ('LIMA+MAGDALENA VIEJA', 49)),\n",
       " ('PICOTA+TRES UNIDOS', ('PICOTA+TRES-UNIDOS', 100)),\n",
       " ('PIURA+26 DE OCTUBRE', ('PIURA+VEINTISEIS DE OCTUBRE', 87)),\n",
       " ('SAN MARTIN+PAPAPLAYA', ('SAN MARTIN+PAPA-PLAYA', 98)),\n",
       " ('SECHURA+RINCONADA LLICUAR', ('SECHURA+RINCONADA-LLICUAR', 100)),\n",
       " ('TACNA+LA YARADA-LOS PALOS', ('TACNA+LA YARADA LOS PALOS', 100)),\n",
       " ('TARATA+ESTIQUE-PAMPA', ('TARATA+ESTIQUE PAMPA', 100)),\n",
       " ('VILCAS HUAMAN+ACCOMARCA', ('VILCAS-HUAMAN+ACCOMARCA', 100)),\n",
       " ('VILCAS HUAMAN+CARHUANCA', ('VILCAS-HUAMAN+CARHUANCA', 100)),\n",
       " ('VILCAS HUAMAN+CONCEPCION', ('VILCAS-HUAMAN+CONCEPCION', 100)),\n",
       " ('VILCAS HUAMAN+HUAMBALPA', ('VILCAS-HUAMAN+HUAMBALPA', 100)),\n",
       " ('VILCAS HUAMAN+INDEPENDENCIA', ('VILCAS-HUAMAN+INDEPENDENCIA', 100)),\n",
       " ('VILCAS HUAMAN+SAURAMA', ('VILCAS-HUAMAN+SAURAMA', 100)),\n",
       " ('VILCAS HUAMAN+VILCAS HUAMAN', ('VILCAS-HUAMAN+VILCAS HUAMAN', 100)),\n",
       " ('VILCAS HUAMAN+VISCHONGO', ('VILCAS-HUAMAN+VISCHONGO', 100))]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pick the closest match from nomatch_gdf for a value in nomatch_df\n",
    "from thefuzz import process\n",
    "[(dis,process.extractOne(dis,nomatch_gdf)) for dis in sorted(nomatch_df)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ba7847-e9b3-47fe-9a65-9e93472eddc3",
   "metadata": {},
   "source": [
    "If you are comfortable, you prepare a _dictionary_ of changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a892fedc-0d65-46bf-9f99-73dc01e409c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ANGARAES+HUANCA-HUANCA': 'ANGARAES+HUANCA HUANCA',\n",
       " 'ANGARAES+HUAYLLAY GRANDE': 'ANGARAES+HUALLAY GRANDE',\n",
       " 'AYMARAES+CARAYBAMBA': 'AYMARAES+CARAIBAMBA',\n",
       " 'AYMARAES+HUAYLLO': 'AYMARAES+IHUAYLLO',\n",
       " 'CHINCHEROS+ANCO_HUALLO': 'CHINCHEROS+ANCO HUALLO',\n",
       " 'HUAMANGA+SAN JOSE DE TICLLAS': 'HUAMANGA+SAN JOSE  DE TICLLAS',\n",
       " 'HUARAZ+PAMPAS': 'HUARAZ+PAMPAS GRANDE',\n",
       " 'ICA+SAN JOSE DE LOS MOLINOS': 'ICA+SAN JOSE DE  LOS MOLINOS',\n",
       " 'JAUJA+MASMA CHICCHE': 'JAUJA+MASMA-CHICCHE',\n",
       " 'JAUJA+TUNAN MARCA': 'JAUJA+TUNAN-MARCA',\n",
       " 'LEONCIO PRADO+DANIEL ALOMIAS ROBLES': 'LEONCIO PRADO+DANIEL ALOMIA ROBLES',\n",
       " 'LIMA+PUEBLO LIBRE': 'LIMA+MAGDALENA VIEJA',\n",
       " 'PICOTA+TRES UNIDOS': 'PICOTA+TRES-UNIDOS',\n",
       " 'PIURA+26 DE OCTUBRE': 'PIURA+VEINTISEIS DE OCTUBRE',\n",
       " 'SAN MARTIN+PAPAPLAYA': 'SAN MARTIN+PAPA-PLAYA',\n",
       " 'SECHURA+RINCONADA LLICUAR': 'SECHURA+RINCONADA-LLICUAR',\n",
       " 'TACNA+LA YARADA-LOS PALOS': 'TACNA+LA YARADA LOS PALOS',\n",
       " 'TARATA+ESTIQUE-PAMPA': 'TARATA+ESTIQUE PAMPA',\n",
       " 'VILCAS HUAMAN+ACCOMARCA': 'VILCAS-HUAMAN+ACCOMARCA',\n",
       " 'VILCAS HUAMAN+CARHUANCA': 'VILCAS-HUAMAN+CARHUANCA',\n",
       " 'VILCAS HUAMAN+CONCEPCION': 'VILCAS-HUAMAN+CONCEPCION',\n",
       " 'VILCAS HUAMAN+HUAMBALPA': 'VILCAS-HUAMAN+HUAMBALPA',\n",
       " 'VILCAS HUAMAN+INDEPENDENCIA': 'VILCAS-HUAMAN+INDEPENDENCIA',\n",
       " 'VILCAS HUAMAN+SAURAMA': 'VILCAS-HUAMAN+SAURAMA',\n",
       " 'VILCAS HUAMAN+VILCAS HUAMAN': 'VILCAS-HUAMAN+VILCAS HUAMAN',\n",
       " 'VILCAS HUAMAN+VISCHONGO': 'VILCAS-HUAMAN+VISCHONGO'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# is this OK?\n",
    "\n",
    "changesDis_df={dis:process.extractOne(dis,nomatch_gdf)[0] for dis in sorted(nomatch_df)}\n",
    "changesDis_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a2d81f-93eb-4f2f-b7ec-32faac5be6c0",
   "metadata": {},
   "source": [
    "Now, make the replacements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5b7b379-d869-405b-9593-c37afa881943",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadis.replace({'provDist':changesDis_df},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352c78fe-1b57-474b-b30a-0c7cea12ea4e",
   "metadata": {},
   "source": [
    "Now the merge can happen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48835a7d-b7ea-47e3-b96d-720520109d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 1874 entries, 0 to 1873\n",
      "Data columns (total 16 columns):\n",
      " #   Column                    Non-Null Count  Dtype   \n",
      "---  ------                    --------------  -----   \n",
      " 0   DEPARTAMEN                1874 non-null   object  \n",
      " 1   PROVINCIA                 1874 non-null   object  \n",
      " 2   DISTRITO                  1874 non-null   object  \n",
      " 3   INSTITUCIO                1874 non-null   object  \n",
      " 4   geometry                  1874 non-null   geometry\n",
      " 5   provDist                  1874 non-null   object  \n",
      " 6   Ubigeo                    1874 non-null   object  \n",
      " 7   Departamento              1874 non-null   object  \n",
      " 8   Provincia                 1874 non-null   object  \n",
      " 9   Distrito                  1874 non-null   object  \n",
      " 10  Poblacion                 1874 non-null   int64   \n",
      " 11  Superficie                1874 non-null   float64 \n",
      " 12  IDH2019                   1874 non-null   float64 \n",
      " 13  Educ_sec_comp2019_pct     1874 non-null   float64 \n",
      " 14  NBI2017_pct               1874 non-null   float64 \n",
      " 15  Viv_sin_serv_hig2017_pct  1874 non-null   float64 \n",
      "dtypes: float64(5), geometry(1), int64(1), object(9)\n",
      "memory usage: 234.4+ KB\n"
     ]
    }
   ],
   "source": [
    "datadisMap=mapdis.merge(datadis, on='provDist')\n",
    "# check\n",
    "datadisMap.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1919efb-07bd-4e54-95e7-7a9f4f4e4515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEPARTAMEN</th>\n",
       "      <th>PROVINCIA</th>\n",
       "      <th>DISTRITO</th>\n",
       "      <th>geometry</th>\n",
       "      <th>Ubigeo</th>\n",
       "      <th>Poblacion</th>\n",
       "      <th>Superficie</th>\n",
       "      <th>IDH2019</th>\n",
       "      <th>Educ_sec_comp2019_pct</th>\n",
       "      <th>NBI2017_pct</th>\n",
       "      <th>Viv_sin_serv_hig2017_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TACNA</td>\n",
       "      <td>TACNA</td>\n",
       "      <td>CORONEL GREGORIO ALBARRACIN LANCHIPA</td>\n",
       "      <td>POLYGON ((-70.17413 -18.12896, -70.17461 -18.1...</td>\n",
       "      <td>230110</td>\n",
       "      <td>123662</td>\n",
       "      <td>187.74</td>\n",
       "      <td>0.578968</td>\n",
       "      <td>71.178389</td>\n",
       "      <td>15.8</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TACNA</td>\n",
       "      <td>TACNA</td>\n",
       "      <td>POCOLLAY</td>\n",
       "      <td>POLYGON ((-69.93475 -17.92557, -69.90467 -17.9...</td>\n",
       "      <td>230108</td>\n",
       "      <td>22319</td>\n",
       "      <td>265.65</td>\n",
       "      <td>0.645954</td>\n",
       "      <td>75.825743</td>\n",
       "      <td>16.1</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TACNA</td>\n",
       "      <td>TACNA</td>\n",
       "      <td>CALANA</td>\n",
       "      <td>POLYGON ((-70.11604 -17.91106, -70.11457 -17.9...</td>\n",
       "      <td>230103</td>\n",
       "      <td>3338</td>\n",
       "      <td>108.38</td>\n",
       "      <td>0.564102</td>\n",
       "      <td>77.829717</td>\n",
       "      <td>15.9</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TACNA</td>\n",
       "      <td>TACNA</td>\n",
       "      <td>TACNA</td>\n",
       "      <td>POLYGON ((-70.3149 -17.94498, -70.30682 -17.95...</td>\n",
       "      <td>230101</td>\n",
       "      <td>80845</td>\n",
       "      <td>1877.78</td>\n",
       "      <td>0.696613</td>\n",
       "      <td>75.491958</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TACNA</td>\n",
       "      <td>TACNA</td>\n",
       "      <td>SAMA</td>\n",
       "      <td>POLYGON ((-70.42497 -17.88934, -70.48022 -17.9...</td>\n",
       "      <td>230109</td>\n",
       "      <td>2679</td>\n",
       "      <td>1115.98</td>\n",
       "      <td>0.552622</td>\n",
       "      <td>70.500250</td>\n",
       "      <td>52.4</td>\n",
       "      <td>10.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DEPARTAMEN PROVINCIA                              DISTRITO  \\\n",
       "0      TACNA     TACNA  CORONEL GREGORIO ALBARRACIN LANCHIPA   \n",
       "1      TACNA     TACNA                              POCOLLAY   \n",
       "2      TACNA     TACNA                                CALANA   \n",
       "3      TACNA     TACNA                                 TACNA   \n",
       "4      TACNA     TACNA                                  SAMA   \n",
       "\n",
       "                                            geometry  Ubigeo  Poblacion  \\\n",
       "0  POLYGON ((-70.17413 -18.12896, -70.17461 -18.1...  230110     123662   \n",
       "1  POLYGON ((-69.93475 -17.92557, -69.90467 -17.9...  230108      22319   \n",
       "2  POLYGON ((-70.11604 -17.91106, -70.11457 -17.9...  230103       3338   \n",
       "3  POLYGON ((-70.3149 -17.94498, -70.30682 -17.95...  230101      80845   \n",
       "4  POLYGON ((-70.42497 -17.88934, -70.48022 -17.9...  230109       2679   \n",
       "\n",
       "   Superficie   IDH2019  Educ_sec_comp2019_pct  NBI2017_pct  \\\n",
       "0      187.74  0.578968              71.178389         15.8   \n",
       "1      265.65  0.645954              75.825743         16.1   \n",
       "2      108.38  0.564102              77.829717         15.9   \n",
       "3     1877.78  0.696613              75.491958          7.4   \n",
       "4     1115.98  0.552622              70.500250         52.4   \n",
       "\n",
       "   Viv_sin_serv_hig2017_pct  \n",
       "0                       0.8  \n",
       "1                       0.9  \n",
       "2                       3.3  \n",
       "3                       0.6  \n",
       "4                      10.8  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bye=['Departamento', 'Provincia', 'Distrito','INSTITUCIO','provDist']\n",
    "datadisMap.drop(columns=bye,inplace=True)\n",
    "\n",
    "# keeping\n",
    "datadisMap.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4944a216-12d8-423c-9461-ea8a28c06c69",
   "metadata": {},
   "source": [
    "## Mining one variable\n",
    "\n",
    "In the session on [Intro to GeoDF](https://cienciadedatosespacial.github.io/intro_geodataframe/) we did a lot on this. The main idea was simply to know the behavior of one variable, and plot it as a choropleth map.\n",
    "\n",
    "In this case, **spatial properties** of the data were _NOT_ used at all, for example:\n",
    "\n",
    "1) Descriptive stats would be same in a simple data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d813c9-d01d-40f4-b284-57e9a87e41b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistics\n",
    "datadisMap.IDH2019.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d75250",
   "metadata": {},
   "source": [
    "2) A histogram would be same in a simple data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c75d39e-f2b9-4c7d-9104-eaf64bf70413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sea\n",
    "\n",
    "sea.histplot(datadisMap.IDH2019, color='yellow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83007cf5",
   "metadata": {},
   "source": [
    "3. Transform and Discretize: We also learned that we could rescale and discretize. But, given this behavior, bell-shaped,  we just need to discretize; which I will simply do using the _fisherjenks_ scheme:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d85b70-12c8-430a-8a85-bdb6b74cafd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadisMap.explore(\n",
    "    column=\"IDH2019\", \n",
    "    scheme=\"fisherjenks\",\n",
    "    legend=True,  \n",
    "    tooltip=False, \n",
    "    popup=['DEPARTAMEN', 'PROVINCIA', 'DISTRITO'],  # show popup (on-click)\n",
    "    legend_kwds=dict(colorbar=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb9ee6b-4c2f-4944-8021-b312bd0036d7",
   "metadata": {},
   "source": [
    "## Spatial Properties: determining the _neighborhood_\n",
    "\n",
    "We can compute the neighborhood for each object in a map using different options:\n",
    "\n",
    "1. The polygons that share borders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86843321-186e-4802-aba4-3e91a6b1b14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from libpysal.weights import Queen, Rook, KNN\n",
    "\n",
    "# rook\n",
    "w_rook = Rook.from_dataframe(datadisMap,use_index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885a72d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_rook.islands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7486edd8",
   "metadata": {},
   "source": [
    "2. The polygons that share at least a point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb99fe0e-1653-4bc7-b999-89ad9d6db6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# queen\n",
    "w_queen = Queen.from_dataframe(datadisMap,use_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3b3b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_queen.islands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea239b8",
   "metadata": {},
   "source": [
    "Let me show the islands detected in the previous steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72fe932",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadisMap.iloc[w_queen.islands,:].explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08456cc",
   "metadata": {},
   "source": [
    "The presence of _islands_ will be problematic in more complex applications. An alternative is:\n",
    "\n",
    "3) Nearest neighbors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb5474b-da2d-436e-8e76-a4ba23149635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k=8 nearest neighbors\n",
    "w_knn8 = KNN.from_dataframe(datadisMap, k=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ea6cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_knn8.islands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a34f9f-ba61-42fe-b6ea-d1f33b536920",
   "metadata": {},
   "source": [
    "Let's understand the differences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d731009a-8404-4f55-bcf0-c392e448dd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first district in the GDF:\n",
    "datadisMap.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0c2161-2d95-49f9-b6b6-edef8be67895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# amount of neighbors of that district\n",
    "len(w_rook.neighbors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a26e817-e6b4-4e52-a8ac-5ff1409d6ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# details\n",
    "datadisMap.iloc[w_rook.neighbors[0],]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0070510f-20cb-4251-a91b-d7fe14eb6563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the neighbor\n",
    "datadisMap.iloc[w_rook.neighbors[0] ,].plot(facecolor=\"yellow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2533f22-607c-4357-98d8-b5d11bb100d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see whole area\n",
    "base=datadisMap[datadisMap.PROVINCIA==\"TACNA\"].plot()\n",
    "datadisMap.iloc[w_rook.neighbors[0] ,].plot(ax=base,facecolor=\"yellow\",edgecolor='k')\n",
    "datadisMap.head(1).plot(ax=base,facecolor=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a85f104-870c-41f1-9d38-3a8c60735556",
   "metadata": {},
   "source": [
    "Let's do the same with queen neighbors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff41c1e4-b3e5-4bf8-8e71-f324b0359a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many\n",
    "len(w_queen.neighbors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c1d332-ee6f-4618-96c0-1fe9ece97e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# details\n",
    "datadisMap.iloc[w_queen.neighbors[0] ,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76585272-7591-4b48-b9df-e057995011bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see\n",
    "datadisMap.iloc[w_queen.neighbors[0] ,].plot(facecolor=\"yellow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a6bda9-5af0-4245-92ce-dc6e8f9b9aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# whole area\n",
    "base=datadisMap[datadisMap.PROVINCIA==\"TACNA\"].plot()\n",
    "datadisMap.iloc[w_queen.neighbors[0] ,].plot(ax=base,facecolor=\"yellow\",edgecolor='k')\n",
    "datadisMap.head(1).plot(ax=base,facecolor=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315b82b0",
   "metadata": {},
   "source": [
    "What about the _eight_ closest ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfa0517-5f72-4c1f-817b-c1df6a4bfaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_knn8.neighbors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67397df-57e1-4d0e-9a19-30717eec3eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "base=datadisMap[datadisMap.PROVINCIA==\"TACNA\"].plot()\n",
    "datadisMap.iloc[w_knn8.neighbors[0],].plot(ax=base,facecolor=\"yellow\")\n",
    "datadisMap.head(1).plot(ax=base,facecolor=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbbd2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what about k=4\n",
    "\n",
    "w_knn4 = KNN.from_dataframe(datadisMap, k=4)\n",
    "\n",
    "base=datadisMap[datadisMap.PROVINCIA==\"TACNA\"].plot()\n",
    "datadisMap.iloc[w_knn4.neighbors[0],].plot(ax=base,facecolor=\"yellow\")\n",
    "datadisMap.head(1).plot(ax=base,facecolor=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd23b4aa-1110-4743-a658-065cd8c925f9",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "\n",
    "<div class=\"alert-success\">\n",
    "        \n",
    "Compute the neighbors of the capital of your country. Plot the results for each of the options.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1899e2-554d-41ce-b38b-0830802ccaae",
   "metadata": {},
   "source": [
    "## Global spatial correlation\n",
    "\n",
    "If a spatial unit (a row) value in a variable is correlated with values of the neighbors, you know that proximity is interfering with the interpretation.\n",
    "\n",
    "We need the neighboorhood matrix (the weight matrix) to compute spatial correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59143e63-f478-419e-a84a-3617f5c6fc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(*w_knn8.full()) # 1 means both are neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0721a79",
   "metadata": {},
   "source": [
    "If we standardize by row, the neighboor adds to 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b103792-bf59-4965-bf9a-17d51be8b49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needed for spatial correlation\n",
    "w_knn8.transform = 'R'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57356f5-5d92-48e7-b135-12ce0e0ea09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after transformation\n",
    "pd.DataFrame(*w_knn8.full()).head(12).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab308c8-26ad-45bb-aa05-5462cd07fc5c",
   "metadata": {},
   "source": [
    "Spatial correlation is measured by the Moran's I statistic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aaedad-e443-407c-9146-3b87c94f237c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from esda.moran import Moran\n",
    "\n",
    "moranIDH = Moran(datadisMap['IDH2019'], w_knn8)\n",
    "moranIDH.I,moranIDH.p_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17dab87-7709-405e-afbe-605e10688d18",
   "metadata": {},
   "source": [
    "A significant Moran's I suggest spatial correlation. Let's see the spatial scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f69e7e5-a4d8-4d31-be91-f295cfb19f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from splot.esda import moran_scatterplot\n",
    "\n",
    "fig, ax = moran_scatterplot(moranIDH, aspect_equal=True)\n",
    "ax.set_xlabel('IDH_std')\n",
    "ax.set_ylabel('SpatialLag_IDH_std');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ccfa77-4bc2-41b0-95d4-7bf743cac51a",
   "metadata": {},
   "source": [
    "### Exercise 7\n",
    "\n",
    "<div class=\"alert-success\">\n",
    "    \n",
    "1. Compute the Moran's coefficient for **one** of your three  numeric variables.\n",
    "    \n",
    "2. Make a scatter plot for each variable.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6a56a5-c9ff-4642-9e57-a98b9195c867",
   "metadata": {},
   "source": [
    "## Local Spatial Correlation\n",
    "\n",
    "We can compute a Local Index of Spatial Association (LISA -local Moran) for each map object. That will help us find spatial clusters (spots) and spatial outliers:\n",
    "\n",
    "* A **hotSpot** is a polygon whose value in the variable is high AND is surrounded with polygons with also high values.\n",
    "\n",
    "* A **coldSpot** is a polygon whose value in the variable is low AND is surrounded with polygons with also low values.\n",
    "\n",
    "* A **coldOutlier** is a polygon whose value in the variable is low BUT is surrounded with polygons with  high values.\n",
    "\n",
    "* A **hotOutlier** is a polygon whose value in the variable is high BUT is surrounded with polygons with  low values.\n",
    "\n",
    "It is also possible that no significant correlation is detected. Let's see those values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0800fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A LISA for each district using IDH2019\n",
    "from esda.moran import Moran_Local\n",
    "lisaIDH = Moran_Local(y=datadisMap['IDH2019'], w=w_knn8,seed=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5eaddb-439a-45af-9ca4-c2a833576c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = moran_scatterplot(lisaIDH,p=0.05)\n",
    "ax.set_xlabel('IDH_std')\n",
    "ax.set_ylabel('SpatialLag_IDH_std');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3025f0",
   "metadata": {},
   "source": [
    "You find that a district is in a **quadrant**. If the district is NOT grey, then the LISA is significant. Let's represent that information in a map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5ee422-356e-472a-ba16-7a09f1daeefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from splot.esda import lisa_cluster\n",
    "f, ax = plt.subplots(1, figsize=(12, 12))\n",
    "plt.title('Spots and Outliers')\n",
    "fig = lisa_cluster(lisaIDH, \n",
    "                   datadisMap,ax=ax,\n",
    "                   legend_kwds={'loc': 'center left', \n",
    "                                'bbox_to_anchor': (0.7, 0.6)});\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5acf306-b47c-4914-b050-e2a32b5ad43a",
   "metadata": {},
   "source": [
    "Let me add the informtion in lisaIDH to the GeoDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b627cccc-7123-45a0-ba53-9f661bac77f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quadrant, # significance\n",
    "lisaIDH.q, lisaIDH.p_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bedff6-0276-42e5-bc60-118274bf0151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quadrant: 1 HH,  2 LH,  3 LL,  4 HL\n",
    "pd.Series(lisaIDH.q).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad08c195-9c11-4e38-925f-42aa620a8f9c",
   "metadata": {},
   "source": [
    "The info in **lisaIDH.q** can not be used right away, we need to add if the local spatial correlation is significant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24bb3f7-49c0-4fca-9d36-4b19bf512ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadisMap['IDH_quadrant']=[l if p <0.05 else 0 for l,p in zip(lisaIDH.q,lisaIDH.p_sim)  ]\n",
    "datadisMap['IDH_quadrant'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b86cd7-af02-4667-8cdc-adbcacf236c8",
   "metadata": {},
   "source": [
    "Now, we recode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e05f70-16d3-4be1-8fd7-89b6be715f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [ '0 no_sig', '1 hotSpot', '2 coldOutlier', '3 coldSpot', '4 hotOutlier']\n",
    "\n",
    "datadisMap['IDH_quadrant_names']=[labels[i] for i in datadisMap['IDH_quadrant']]\n",
    "\n",
    "datadisMap['IDH_quadrant_names'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54771dcd-a7b6-4429-bd49-3e785f2dd1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# custom colors\n",
    "from matplotlib import colors\n",
    "myColMap = colors.ListedColormap([ 'white', 'pink', 'cyan', 'azure','red'])\n",
    "\n",
    "# Set up figure and ax\n",
    "f, ax = plt.subplots(1, figsize=(12,12))\n",
    "# Plot unique values choropleth including\n",
    "# a legend and with no boundary lines\n",
    "\n",
    "plt.title('Spots and Outliers')\n",
    "\n",
    "datadisMap.plot(column='IDH_quadrant_names', \n",
    "                categorical=True,\n",
    "                cmap=myColMap,\n",
    "                linewidth=0.1, \n",
    "                edgecolor='k',\n",
    "                legend=True,\n",
    "                legend_kwds={'loc': 'center left', \n",
    "                             'bbox_to_anchor': (0.7, 0.6)},\n",
    "                ax=ax)\n",
    "# Remove axis\n",
    "ax.set_axis_off()\n",
    "# Display the map\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1b9f05-a42d-4360-b403-3934344d4327",
   "metadata": {},
   "source": [
    "### Exercise 8\n",
    "\n",
    "<div class=\"alert-success\">\n",
    "    \n",
    "1. Compute the Local Moran for the variables in your data that have significant spatial correlation.\n",
    "    \n",
    "2. Create a new column for each of those variables, with a label ('0 no_sig', '1 hotSpot', '2 coldOutlier', '3 coldSpot', '4 hotOutlier').\n",
    "\n",
    "3. Prepare a map for each of the variables analyzed, showing the spots and outliers.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5d25af",
   "metadata": {},
   "source": [
    "## Mining several variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51761cd",
   "metadata": {},
   "source": [
    "Let me select some columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65be709a",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_variables = ['Educ_sec_comp2019_pct',\n",
    "                     'NBI2017_pct', \n",
    "                     'Viv_sin_serv_hig2017_pct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5934586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see distribution\n",
    "sea.boxplot(datadisMap[selected_variables])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2998446",
   "metadata": {},
   "source": [
    "Let me check their monotony:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e81b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadisMap[selected_variables].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8054af",
   "metadata": {},
   "outputs": [],
   "source": [
    "sea.pairplot(\n",
    "    datadisMap[selected_variables], kind=\"reg\", diag_kind=\"kde\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dcf5c5",
   "metadata": {},
   "source": [
    "Here, we can reverse the values of *Educ_sec_comp2019_pct*. First let me standardize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e87d2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "normalized_data = scaler.fit_transform(datadisMap[selected_variables])\n",
    "sea.displot(pd.melt(pd.DataFrame(normalized_data,columns=selected_variables)),\n",
    "            x=\"value\", hue=\"variable\",kind=\"kde\",\n",
    "            log_scale=(False,False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df652d1c",
   "metadata": {},
   "source": [
    "Let me create new variables with the standardized values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de888e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new names\n",
    "selected_variables_new_std=[s+'_std' for s in selected_variables]\n",
    "\n",
    "# add colunms\n",
    "datadisMap[selected_variables_new_std]=normalized_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fdfd1b",
   "metadata": {},
   "source": [
    "Now, it is easy to reverse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd6a431",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadisMap['Educ_sec_NO_comp2019_pct_std']=-1*datadisMap.Educ_sec_comp2019_pct_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be16ade3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as a result:\n",
    "selected_variables_new_std = ['Educ_sec_NO_comp2019_pct_std',\n",
    "                     'NBI2017_pct_std', \n",
    "                     'Viv_sin_serv_hig2017_pct_std']\n",
    "sea.pairplot(\n",
    "    datadisMap[selected_variables_new_std], kind=\"reg\", diag_kind=\"kde\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b007649d",
   "metadata": {},
   "source": [
    "### Conventional Clustering\n",
    "\n",
    "Here, I will use the three variables to create clusters of districts. Let me explore how many clusters could be created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad295ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster import hierarchy as hc\n",
    "\n",
    "\n",
    "Z = hc.linkage(datadisMap[selected_variables_new_std], 'ward')\n",
    "# calculate full dendrogram\n",
    "plt.figure(figsize=(25, 10))\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('cases')\n",
    "plt.ylabel('distance')\n",
    "hc.dendrogram(\n",
    "    Z,\n",
    "    leaf_rotation=90.,  # rotates the x axis labels\n",
    "    leaf_font_size=1,  # font size for the x axis labels\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa45a8ce",
   "metadata": {},
   "source": [
    "The dendogram recommends three groups. Let me request six.\n",
    "\n",
    "Let me use a common hierarchical technique following a agglomerative approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44e4a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering as agnes\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(12345)# Set seed for reproducibility\n",
    "\n",
    "# Initialize the algorithm, requesting 6 clusters\n",
    "model = agnes(linkage=\"ward\", n_clusters=6).fit(datadisMap[selected_variables_new_std])\n",
    "\n",
    "# Assign labels to main data table\n",
    "datadisMap[\"hc_ag6\"] = model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fdcca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see distribution of districts\n",
    "datadisMap[\"hc_ag6\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87068ef",
   "metadata": {},
   "source": [
    "We could try to find the pattern that created the clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757b7721",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadisMap.groupby(\"hc_ag6\")[selected_variables_new_std].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58dd2e3",
   "metadata": {},
   "source": [
    "Let me show you the six groups of districts which have similar behavior in three variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa279c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up figure and ax\n",
    "f, ax = plt.subplots(1, figsize=(9, 9))\n",
    "# Plot unique values choropleth including\n",
    "# a legend and with no boundary lines\n",
    "datadisMap.plot(\n",
    "    column=\"hc_ag6\", categorical=True, legend=True, linewidth=0, ax=ax\n",
    ")\n",
    "# Remove axis\n",
    "ax.set_axis_off()\n",
    "# Display the map\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7386825e",
   "metadata": {},
   "source": [
    "### Regionalization: Spatial Clustering \n",
    "\n",
    "Spatial clustering or Regionalization will force the contiguity of the polygons to make a cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9d5a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify previous funtion call to specify cluster model with spatial constraint\n",
    "\n",
    "model_queen = agnes(linkage=\"ward\", \n",
    "                    n_clusters=6,\n",
    "                    connectivity=w_queen.sparse).fit(datadisMap[selected_variables_new_std])\n",
    "# Fit algorithm to the data\n",
    "datadisMap[\"hc_ag6_wQueen\"] = model_queen.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab01abf",
   "metadata": {},
   "source": [
    "We knew this would happen because we have islands. Then this results may not be satisfactory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8465df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up figure and ax\n",
    "f, ax = plt.subplots(1, figsize=(9, 9))\n",
    "# Plot unique values choropleth including a legend and with no boundary lines\n",
    "datadisMap.plot(\n",
    "    column=\"hc_ag6_wQueen\",\n",
    "    categorical=True,\n",
    "    legend=True,\n",
    "    linewidth=0,\n",
    "    ax=ax,\n",
    ")\n",
    "# Remove axis\n",
    "ax.set_axis_off()\n",
    "# Display the map\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10da7ec9",
   "metadata": {},
   "source": [
    "We have a couple of KNN weight matrices. Let's use those instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2166b078",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wknn8 = agnes(linkage=\"ward\",\n",
    "                    n_clusters=6,\n",
    "                    connectivity=w_knn8.sparse).fit(datadisMap[selected_variables_new_std])\n",
    "datadisMap[\"hc_ag6_wknn8\"] = model_wknn8.labels_\n",
    "\n",
    "\n",
    "model_wknn4 = agnes(linkage=\"ward\",\n",
    "                    n_clusters=6,\n",
    "                    connectivity=w_knn4.sparse).fit(datadisMap[selected_variables_new_std])\n",
    "datadisMap[\"hc_ag6_wknn4\"] = model_wknn4.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0babe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up figure and ax\n",
    "f, ax = plt.subplots(1, figsize=(10, 12))\n",
    "# Plot unique values choropleth including a legend and with no boundary lines\n",
    "datadisMap.plot(\n",
    "    column=\"hc_ag6_wknn8\",\n",
    "    categorical=True,\n",
    "    legend=True,\n",
    "    linewidth=0,\n",
    "    ax=ax,\n",
    ")\n",
    "# Remove axis\n",
    "ax.set_axis_off()\n",
    "# Display the map\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965da01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up figure and ax\n",
    "f, ax = plt.subplots(1, figsize=(10, 12))\n",
    "# Plot unique values choropleth including a legend and with no boundary lines\n",
    "datadisMap.plot(\n",
    "    column=\"hc_ag6_wknn4\",\n",
    "    categorical=True,\n",
    "    legend=True,\n",
    "    linewidth=0,\n",
    "    ax=ax,\n",
    ")\n",
    "# Remove axis\n",
    "ax.set_axis_off()\n",
    "# Display the map\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bab781",
   "metadata": {},
   "source": [
    "We could evaluate two aspects of these clustering results:\n",
    "\n",
    "* “Compactness” of cluster shape, using the isoperimetric quotient (IPQ). This compares the area of the region to the area of a circle with the same perimeter as the region. For this measure, more compact shapes have an IPQ closer to 1, whereas very elongated or spindly shapes will have IPQs closer to zero. For the clustering solutions, we would expect the IPQ to be very small indeed, since the perimeter of a cluster/region gets smaller the more boundaries that members share."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e213fe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from esda import shape as shapestats\n",
    "results={}\n",
    "for cluster_type in (\"hc_ag6_wknn4\", \"hc_ag6_wknn8\", \"hc_ag6\"):\n",
    "    # compute the region polygons using a dissolve\n",
    "    regions = datadisMap[[cluster_type, \"geometry\"]].to_crs(24892).dissolve(by=cluster_type)\n",
    "    # compute the actual isoperimetric quotient for these regions\n",
    "    ipqs = shapestats.isoperimetric_quotient(regions)\n",
    "    # cast to a dataframe\n",
    "    result = {cluster_type:ipqs}\n",
    "    results.update(result)\n",
    "# stack the series together along columns\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9599c1e1",
   "metadata": {},
   "source": [
    "An alternative could be _convex_hull_ratio_, simply the division of the area of the cluster by the area of its convex hull."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17091459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from esda import shape as shapestats\n",
    "results={}\n",
    "for cluster_type in (\"hc_ag6_wknn4\", \"hc_ag6_wknn8\", \"hc_ag6\"):\n",
    "    # compute the region polygons using a dissolve\n",
    "    regions = datadisMap[[cluster_type, \"geometry\"]].to_crs(24892).dissolve(by=cluster_type)\n",
    "    # compute the actual convex hull quotient for these regions\n",
    "    chullr = shapestats.convex_hull_ratio(regions)\n",
    "    # cast to a dataframe\n",
    "    result = {cluster_type:chullr}\n",
    "    results.update(result)\n",
    "# stack the series together along columns\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972d9146",
   "metadata": {},
   "source": [
    "In both cases, the non spatial clusters do better.\n",
    "\n",
    "* Goodness of fit. Here we have two metrics:\n",
    "    - metrics.calinski_harabasz_score\n",
    "    - silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0decf624",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "fit_scores = []\n",
    "for cluster_type in (\"hc_ag6_wknn4\", \"hc_ag6_wknn8\", \"hc_ag6\"):\n",
    "    # compute the CH score\n",
    "    ch_score = metrics.calinski_harabasz_score(\n",
    "        # using scaled variables\n",
    "        datadisMap[selected_variables_new_std],\n",
    "        # using these labels\n",
    "        datadisMap[cluster_type],\n",
    "    )\n",
    "    sil_score = metrics.silhouette_score(\n",
    "        # using scaled variables\n",
    "        datadisMap[selected_variables_new_std],\n",
    "        # using these labels\n",
    "        datadisMap[cluster_type],\n",
    "    )\n",
    "    # and append the cluster type with the CH score\n",
    "    fit_scores.append((cluster_type, ch_score,sil_score))\n",
    "\n",
    "\n",
    "# re-arrange the scores into a dataframe for display\n",
    "pd.DataFrame(\n",
    "    fit_scores, columns=[\"cluster type\", \"CH score\", \"SIL score\"]\n",
    ").set_index(\"cluster type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d123df",
   "metadata": {},
   "source": [
    "Again, the conventional clustering beats the others, as you want bigger values in both.\n",
    "\n",
    "### Exercise 9\n",
    "\n",
    "<div class=\"alert-success\">\n",
    "    \n",
    "Use your three variables to carry out the cluster/regional analysis.\n",
    "    \n",
    "</div>\n",
    "\n",
    "\n",
    "### Conventional Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037f7f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysal.model import spreg\n",
    "\n",
    "dep_var_name=['NBI2017_pct']\n",
    "ind_vars_names=['Educ_sec_comp2019_pct','Viv_sin_serv_hig2017_pct']\n",
    "\n",
    "\n",
    "ols_model = spreg.OLS(\n",
    "    # Dependent variable\n",
    "    datadisMap[dep_var_name].values,\n",
    "    # Independent variables\n",
    "    datadisMap[ind_vars_names].values,\n",
    "    w=w_knn8,\n",
    "    spat_diag = True,\n",
    "    moran=True,\n",
    "    # Dependent variable name\n",
    "    name_y=dep_var_name[0],\n",
    "    # Independent variable name\n",
    "    name_x=ind_vars_names)\n",
    "\n",
    "print(ols_model.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb40c6e8",
   "metadata": {},
   "source": [
    "### Spatial Regression\n",
    "\n",
    "* Spatial Lag Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41165509",
   "metadata": {},
   "outputs": [],
   "source": [
    "moranNBI = Moran(datadisMap[dep_var_name], w_knn8)\n",
    "moranNBI.I,moranNBI.p_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4509eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = moran_scatterplot(moranNBI, aspect_equal=True)\n",
    "ax.set_xlabel('NBI')\n",
    "ax.set_ylabel('SpatialLag_NBI');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d795a272",
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_model = spreg.ML_Lag(\n",
    "    # Dependent variable\n",
    "    datadisMap[dep_var_name].values,\n",
    "    # Independent variables\n",
    "    datadisMap[ind_vars_names].values,\n",
    "    w=w_knn8,\n",
    "    # Dependent variable name\n",
    "    name_y=dep_var_name[0],\n",
    "    # Independent variable name\n",
    "    name_x=ind_vars_names\n",
    "    )\n",
    "\n",
    "print(lag_model.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a4dcb9",
   "metadata": {},
   "source": [
    "* Spatial Error Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2152eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "moranError = Moran(ols_model.u, w_knn8)\n",
    "moranError.I,moranError.p_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20f8e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = moran_scatterplot(moranError, aspect_equal=True)\n",
    "ax.set_xlabel('OlsError')\n",
    "ax.set_ylabel('SpatialOlsError');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937f16a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_model = spreg.ML_Error(\n",
    "    # Dependent variable\n",
    "    datadisMap[dep_var_name].values,\n",
    "    # Independent variables\n",
    "    datadisMap[ind_vars_names].values,\n",
    "    w=w_knn8,\n",
    "    # Dependent variable name\n",
    "    name_y=dep_var_name[0],\n",
    "    # Independent variable name\n",
    "    name_x=ind_vars_names\n",
    "    )\n",
    "\n",
    "print(err_model.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7175b6",
   "metadata": {},
   "source": [
    "* Spatial Error Regression, correcting heteroscedasticy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d5cab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_Het_model = spreg.GM_Error_Het(    \n",
    "    # Dependent variable\n",
    "    datadisMap[dep_var_name].values,\n",
    "    # Independent variables\n",
    "    datadisMap[ind_vars_names].values,\n",
    "    # Spatial weights matrix\n",
    "    w=w_knn8,\n",
    "    # Dependent variable name\n",
    "    name_y=dep_var_name[0],\n",
    "    # Independent variable name\n",
    "    name_x=ind_vars_names,\n",
    ")\n",
    "print(error_Het_model.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d857a017",
   "metadata": {},
   "source": [
    "### Exercise 10\n",
    "\n",
    "<div class=\"alert-success\">\n",
    "    \n",
    "Use your three variables to carry out regression analysis (conventional and spatial).\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c037d70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
